{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "mount_file_id": "1daSJtdn_AOYUWkjqZY-aeWji_0McF8Dk",
      "authorship_tag": "ABX9TyNG/a23WyJUaiQbkrZPVqjf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CCanxue/CCanxue/blob/main/Pytorch%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%AE%9E%E7%8E%B0\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Pytorch预备知识与线性回归实现"
      ],
      "metadata": {
        "id": "ZgDFhh9AIQYc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crsCAZ1HuMXq",
        "outputId": "089f9b51-bd70-4ec8-c13c-ae02c036a292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4.], dtype=torch.float64) tensor(5., dtype=torch.float64)\n",
            "tensor(11., dtype=torch.float64)\n",
            "tensor([ 8.,  9., 10., 11.], dtype=torch.float64)\n",
            "tensor([[0., 1., 2., 3.],\n",
            "        [4., 5., 6., 7.]], dtype=torch.float64)\n",
            "[1 2 3 4]\n",
            "12\n",
            "tensor([[9., 9., 9., 9.],\n",
            "        [9., 9., 9., 9.],\n",
            "        [9., 9., 9., 9.]], dtype=torch.float64)\n",
            "139714159582672\n",
            "139714185279824\n",
            "tensor([[108., 108., 108., 108., 108.]], dtype=torch.float64)\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "#预备知识练习\n",
        "#id() dir() help() x[a:b] 从a到b，不包括b  len(x) axis0上元素个数 矩阵运算用：x+=y x*=y  torch.cat() 矩阵拼接\n",
        "#A.mean(axis=0)=A.sum(axis=0)/A.shape[0]  torch.matmul() 矩阵/向量乘积均适用\n",
        "import torch\n",
        "import numpy as np\n",
        "z=np.ones((4,5))\n",
        "z=torch.tensor(z)\n",
        "x=torch.arange(12,dtype=torch.float64)\n",
        "print(x[1:5],x[5])  \n",
        "print(x[-1])   #最后一位\n",
        "x=x.reshape((3,-1))\n",
        "print(x[-1]) \n",
        "print(x[0:-1])  \n",
        "x[0:-1]=9  #x中除最后一行的其他元素，不管x是几维\n",
        "x[:]=9   #x中的全部元素\n",
        "y=torch.tensor([1,2,3,4])\n",
        "y=y.numpy()\n",
        "print(y)\n",
        "print(x.numel())  #全部元素的个数\n",
        "print(x)\n",
        "print(id(x))\n",
        "x=torch.mm(x,z)   #矩阵乘法  dot为向量点积\n",
        "print(id(x))\n",
        "print(x.sum(axis=0,keepdims=True))\n",
        "print(len(z))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#计算梯度\n",
        "import torch\n",
        "x=torch.arange(4,dtype=torch.float32,requires_grad=True)\n",
        "x=x.reshape(2,2)\n",
        "x.retain_grad()\n",
        "y=torch.matmul(x,x)*2+6\n",
        "y.backward(torch.ones_like(x))\n",
        "print(x.grad)"
      ],
      "metadata": {
        "id": "Z7C_-U5cyMIl",
        "outputId": "9e10afbf-055e-43ec-86d0-133166b607df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 6., 14.],\n",
            "        [10., 18.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#三种输出字符串格式化方法\n",
        "age=20\n",
        "name=\"sl w\"\n",
        "school=\"HUST\"\n",
        "print(\"my name is %s,my age is %d,and my school is %s\"%(name,age,school))\n",
        "\n",
        "rar={\"name\":\"sl w\",\"age\":20,\"school\":\"HUST\"}\n",
        "print(\"my name is {name},my age is {age},and my school is {school}\".format(**rar))\n",
        "\n",
        "print(f\"my name is {name},my age is {age},and my school is {school}\") #速度最快\n",
        "print(f\"my name is {rar['name']},my age is {rar['age']},and my school is {rar['school']}\")"
      ],
      "metadata": {
        "id": "CZCBm1uv9bOi",
        "outputId": "3614dff2-71cf-4495-b31f-77c39fb03329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my name is sl w,my age is 20,and my school is HUST\n",
            "my name is sl w,my age is 20,and my school is HUST\n",
            "my name is sl w,my age is 20,and my school is HUST\n",
            "my name is sl w,my age is 20,and my school is HUST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "def synthetic_data(w,b,num_examples):\n",
        "  x=torch.normal(0,1,(num_examples,len(w)))\n",
        "  y=torch.matmul(x,w)+b   \n",
        "  y+=torch.normal(0,0.01,y.shape) #节省内存\n",
        "  return x,y.reshape((-1,1))\n",
        "true_w=torch.tensor([2.,-3.4])\n",
        "true_b=4.2\n",
        "features,labels=synthetic_data(true_w,true_b,1000)\n",
        "def data_iter(batch_size,features,labels):\n",
        "  num_examples=len(features)\n",
        "  indices=list(range(num_examples))\n",
        "  random.shuffle(indices) #洗牌\n",
        "  for i in range(0,num_examples,batch_size):\n",
        "    batch_indices=torch.tensor(indices[i:min(i+batch_size,num_examples)])\n",
        "    yield features[batch_indices],labels[batch_indices]\n",
        "batch_size=10\n",
        "w=torch.normal(0,0.01,(2,1),requires_grad=True)\n",
        "b=torch.zeros(1,requires_grad=True)\n",
        "def linreg(x,w,b):\n",
        "  return torch.matmul(x,w)+b\n",
        "def squared_loss(y_hat,y):\n",
        "  return (y_hat-y.reshape(y_hat.shape))**2/2\n",
        "def sgd(params,lr,batch_size):\n",
        "  with torch.no_grad(): #为了使其后的-=操作正常运行\n",
        "    for param in params:\n",
        "      param-=lr*param.grad/batch_size\n",
        "      param.grad.zero_() #梯度更新\n",
        "lr=0.03\n",
        "num_epochs=3\n",
        "net=linreg\n",
        "loss=squared_loss\n",
        "for epoch in range(num_epochs):\n",
        "  for x,y in data_iter(batch_size,features,labels):\n",
        "    l=loss(net(x,w,b),y)\n",
        "    l.sum().backward()\n",
        "    sgd([w,b],lr,batch_size)\n",
        "  with torch.no_grad(): #上下文管理器\n",
        "    train_l=loss(net(features,w,b),labels)\n",
        "    print(f'epoch{epoch+1},loss{float(train_l.mean()):f}')\n",
        "print(f\"b的估计误差:{b-true_b}\")\n",
        "print(f\"w的估计误差:{w.T-true_w}\")"
      ],
      "metadata": {
        "id": "4SbGP4_T8_wB",
        "outputId": "9d3aaec8-18bd-43bd-f1fb-5ee31a5d81ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch1,loss0.035263\n",
            "epoch2,loss0.000126\n",
            "epoch3,loss0.000049\n",
            "b的估计误差:tensor([-0.0002], grad_fn=<SubBackward0>)\n",
            "w的估计误差:tensor([[0.0001, 0.0007]], grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    }
  ]
}